{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "266445a9",
   "metadata": {},
   "source": [
    "Packages importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ccc412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "from scipy.optimize import least_squares\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad373bf",
   "metadata": {},
   "source": [
    "Funktionen importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca96916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kabsch_algorithm(P, Q):\n",
    "    p_centroid = np.mean(P, axis=0)\n",
    "    q_centroid = np.mean(Q, axis=0)\n",
    "    P_centered = P - p_centroid # Werte werden ins Zentrum des Koordinatensystems verschoben\n",
    "    Q_centered = Q - q_centroid # Werte werden ins Zentrum des Koordinatensystems verschoben\n",
    "    H = P_centered.T @ Q_centered # Korrelationsmatrix\n",
    "    U, S, Vt = svd(H)\n",
    "    V = Vt.T\n",
    "    R = V @ U.T\n",
    "    if np.linalg.det(R) < 0:\n",
    "        V[:,-1] *= -1\n",
    "        R = V @ U.T\n",
    "    t = q_centroid - R @ p_centroid\n",
    "    return R, t\n",
    "\n",
    "def rotation_matrix_from_euler(alpha, beta, gamma):\n",
    "    # Rotationsmatrizen für Eulerwinkel (Z-Y-X)\n",
    "    Rz = np.array([[np.cos(alpha), -np.sin(alpha), 0],\n",
    "                   [np.sin(alpha),  np.cos(alpha), 0],\n",
    "                   [0,              0,             1]])\n",
    "    Ry = np.array([[ np.cos(beta), 0, np.sin(beta)],\n",
    "                   [0,             1, 0],\n",
    "                   [-np.sin(beta), 0, np.cos(beta)]])\n",
    "    Rx = np.array([[1,             0,              0],\n",
    "                   [0, np.cos(gamma), -np.sin(gamma)],\n",
    "                   [0, np.sin(gamma),  np.cos(gamma)]])\n",
    "    return Rz @ Ry @ Rx\n",
    "\n",
    "def residual(params, P, Q):\n",
    "    alpha, beta, gamma, tx, ty, tz = params\n",
    "    R_opt = rotation_matrix_from_euler(alpha, beta, gamma)\n",
    "    t_opt = np.array([tx, ty, tz])\n",
    "    P_transformed = (R_opt @ P.T).T + t_opt\n",
    "    diff = P_transformed - Q\n",
    "    return diff.flatten()\n",
    "\n",
    "\n",
    "def gelenk0_TF(encoder_raw_position):\n",
    "        \"\"\"\n",
    "        Transformation logic for Gelenk 0.\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"a\": 2450.0517124242577,\n",
    "            \"b\": 7867.202696571338,\n",
    "            \"c1\": 5414.61226810207,\n",
    "            \"gamma0\": -1.4348954481458154,\n",
    "            \"inverted\": True,\n",
    "                    }\n",
    "\n",
    "        inverted = params['inverted']\n",
    "        a, b, c1, gamma0 = params['a'], params['b'], params['c1'], params['gamma0']\n",
    "\n",
    "        if (inverted == True):\n",
    "            return (-1) * (np.arccos((a ** 2 + b ** 2 - (c1 + encoder_raw_position) ** 2) / (2 * a * b)) + gamma0)\n",
    "        else:\n",
    "            return np.arccos((a ** 2 + b ** 2 - (c1 + encoder_raw_position) ** 2) / (2 * a * b)) + gamma0\n",
    "        \n",
    "def gelenk1_TF(encoder_raw_position):\n",
    "        \"\"\"\n",
    "        Transformation logic for Gelenk 1.\n",
    "        \"\"\"\n",
    "        params={\n",
    "        \"offset\": 33125,\n",
    "        \"resolution_bit\": 18,\n",
    "        \"inverted\": False}\n",
    "\n",
    "        inverted = params['inverted']\n",
    "        offset = params['offset']\n",
    "        resolution_bit = params['resolution_bit']\n",
    "        gain = pow(2, -resolution_bit) * 2 * np.pi\n",
    "\n",
    "        adjusted_position = (encoder_raw_position - offset) % (2 ** resolution_bit)\n",
    "        transformed_points_1 = []\n",
    "        for position in adjusted_position:\n",
    "            if position > (2 ** resolution_bit) / 2:\n",
    "                value = position - (2 ** resolution_bit)\n",
    "                transformed_points_1.append(value)\n",
    "            else:\n",
    "                 transformed_points_1.append(position)\n",
    "\n",
    "        transformed_points_1 = pd.DataFrame(transformed_points_1, columns=['encoder_1'],index=encoder_raw_position.index)\n",
    "        \n",
    "        if (inverted == False):\n",
    "            return transformed_points_1 * gain\n",
    "        else:\n",
    "            return (-1) * (transformed_points_1 * gain)\n",
    "\n",
    "def gelenk2_TF(encoder_raw_position):\n",
    "        \"\"\"\n",
    "        Transformation logic for Gelenk 2.\n",
    "        \"\"\"\n",
    "\n",
    "        params ={\n",
    "        \"offset\": 669,\n",
    "        \"gain\": 0.0001, \n",
    "        \"inverted\": False}\n",
    "\n",
    "        inverted = params['inverted']\n",
    "        offset = params['offset']\n",
    "        gain = params['gain']\n",
    "    \n",
    "        if (inverted == False):\n",
    "            return (encoder_raw_position - offset) * gain\n",
    "        else:\n",
    "            return (-1) * ((encoder_raw_position - offset) * gain)\n",
    "\n",
    "def gelenk3_TF(encoder_raw_position):\n",
    "        \"\"\"\n",
    "        Transformation logic for Gelenk 3.\n",
    "        \"\"\"\n",
    "\n",
    "        params={\n",
    "        \"offset\": 150339,\n",
    "        \"resolution_bit\": 18,\n",
    "        \"inverted\": False}\n",
    "\n",
    "        inverted = params['inverted']\n",
    "        offset = params['offset']\n",
    "        resolution_bit = params['resolution_bit']\n",
    "        gain = pow(2, -resolution_bit) * 2 * np.pi\n",
    "\n",
    "        adjusted_position = (encoder_raw_position - offset) % (2 ** resolution_bit)\n",
    "        transformed_points_3 = []\n",
    "        for position in adjusted_position:\n",
    "            if position > (2 ** resolution_bit) / 2:\n",
    "                value = position - (2 ** resolution_bit)\n",
    "                transformed_points_3.append(value)\n",
    "            else:\n",
    "                 transformed_points_3.append(position)\n",
    "\n",
    "        transformed_points_3 = pd.DataFrame(transformed_points_3, columns=['encoder_3'],index=encoder_raw_position.index)\n",
    "        \n",
    "        if (inverted == False):\n",
    "            return transformed_points_3 * gain\n",
    "        else:\n",
    "            return (-1) * (transformed_points_3 * gain)\n",
    "        \n",
    "\n",
    "def gelenk4_TF(encoder_raw_position):\n",
    "        \"\"\"\n",
    "        Transformation logic for Gelenk 4.\n",
    "        \"\"\"\n",
    "\n",
    "        params={\n",
    "        \"offset\": 186926,\n",
    "        \"resolution_bit\": 18,\n",
    "        \"inverted\": True}\n",
    "\n",
    "        inverted = params['inverted']\n",
    "        offset = params['offset']\n",
    "        resolution_bit = params['resolution_bit']\n",
    "        gain = pow(2, -resolution_bit) * 2 * np.pi\n",
    "\n",
    "        adjusted_position = (encoder_raw_position - offset) % (2 ** resolution_bit)\n",
    "        transformed_points_4 = []\n",
    "        for position in adjusted_position:\n",
    "            if position > (2 ** resolution_bit) / 2:\n",
    "                value = position - (2 ** resolution_bit)\n",
    "                transformed_points_4.append(value)\n",
    "            else:\n",
    "                 transformed_points_4.append(position)\n",
    "\n",
    "        transformed_points_4 = pd.DataFrame(transformed_points_4, columns=['encoder_4'],index=encoder_raw_position.index)\n",
    "        \n",
    "        if (inverted == False):\n",
    "            return transformed_points_4 * gain\n",
    "        else:\n",
    "            return (-1) * (transformed_points_4 * gain)\n",
    "\n",
    "def gelenk5_TF(encoder_raw_position):\n",
    "        \"\"\"\n",
    "        Transformation logic for Gelenk 5.\n",
    "        \"\"\"\n",
    "\n",
    "        params={\n",
    "        \"offset\": 33459832,\n",
    "        \"gain\": 0.0000343397756528412,\n",
    "        \"inverted\": False}\n",
    "\n",
    "        inverted = params['inverted']\n",
    "        offset = params['offset']\n",
    "        gain = params['gain']\n",
    "\n",
    "        if (inverted == False):\n",
    "            return (encoder_raw_position - offset) * gain\n",
    "        else:\n",
    "            return (-1) * ((encoder_raw_position - offset) * gain)\n",
    "\n",
    "def gelenk6_TF(encoder_raw_position):\n",
    "        \"\"\"\n",
    "        Transformation logic for Gelenk 6.\n",
    "        \"\"\"\n",
    "\n",
    "        params={\n",
    "        \"offset\": 1244,\n",
    "        \"resolution_bit\": 13,\n",
    "        \"inverted\": True}\n",
    "\n",
    "        inverted = params['inverted']\n",
    "        offset = params['offset']\n",
    "        resolution_bit = params['resolution_bit']\n",
    "        gain = pow(2, -resolution_bit) * 2 * np.pi\n",
    "\n",
    "        adjusted_position = (encoder_raw_position - offset) % (2 ** resolution_bit)\n",
    "        transformed_points_6 = []\n",
    "        for position in adjusted_position:\n",
    "            if position > (2 ** resolution_bit) / 2:\n",
    "                value = position - (2 ** resolution_bit)\n",
    "                transformed_points_6.append(value)\n",
    "            else:\n",
    "                 transformed_points_6.append(position)\n",
    "\n",
    "        transformed_points_6 = pd.DataFrame(transformed_points_6, columns=['encoder_6'],index=encoder_raw_position.index)\n",
    "        \n",
    "        if (inverted == False):\n",
    "            return transformed_points_6 * gain\n",
    "        else:\n",
    "            return (-1) * (transformed_points_6 * gain)\n",
    "\n",
    "def gelenk7_TF(encoder_raw_position):\n",
    "        \"\"\"\n",
    "        Transformation logic for Gelenk 7.\n",
    "        \"\"\"\n",
    "\n",
    "        params={\n",
    "        \"offset\": 7266,\n",
    "        \"resolution_bit\": 13,\n",
    "        \"inverted\": False}\n",
    "\n",
    "        inverted = params['inverted']\n",
    "        offset = params['offset']\n",
    "        resolution_bit = params['resolution_bit']\n",
    "        gain = pow(2, -resolution_bit) * 2 * np.pi\n",
    "\n",
    "        adjusted_position = (encoder_raw_position - offset) % (2 ** resolution_bit)\n",
    "        transformed_points_7 = []\n",
    "        for position in adjusted_position:\n",
    "            if position > (2 ** resolution_bit) / 2:\n",
    "                value = position - (2 ** resolution_bit)\n",
    "                transformed_points_7.append(value)\n",
    "            else:\n",
    "                 transformed_points_7.append(position)\n",
    "\n",
    "        transformed_points_7 = pd.DataFrame(transformed_points_7, columns=['encoder_3'],index=encoder_raw_position.index)\n",
    "        \n",
    "        if (inverted == False):\n",
    "            return transformed_points_7 * gain\n",
    "        else:\n",
    "            return (-1) * (transformed_points_7 * gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c16b4",
   "metadata": {},
   "source": [
    "Messdaten aller Messtage 21.01., 01.02., 10.02., 03.03. (Position 1) und 03.03. (Position 2) importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59745f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vom 21.01.2025 importieren und strukturieren\n",
    "data_ts_21_01 = pd.read_csv('../data/Rohdaten_TS_21_01_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "data_encoder_21_01 = pd.read_csv('../data/Encoderwerte_21_01_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_TS_21_01 = pd.read_csv('../data/Rohdaten_TS_21_01_V_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_encoder_21_01 = pd.read_csv('../data/Encoderwerte_21_01_V_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "\n",
    "encoder_points_21_01 = (data_encoder_21_01[['x_Encoder', 'y_Encoder', 'z_Encoder']]/1000)\n",
    "ts_points_21_01 = data_ts_21_01[['x_TS', 'y_TS', 'z_TS']]\n",
    "\n",
    "encoder_points_validation_21_01 = validation_data_encoder_21_01[['x_Encoder', 'y_Encoder', 'z_Encoder']].values/1000\n",
    "ts_points_validation_21_01 = validation_data_TS_21_01[['x_TS', 'y_TS', 'z_TS']].values \n",
    "\n",
    "# Daten vom 01.02.2025 importieren und strukturieren\n",
    "data = pd.read_csv('../data/Modellentwicklung_Encoderwerte.csv', sep=';', index_col=0)\n",
    "raw_data = pd.read_csv('../data/Modellentwicklung_Rohdaten_Totalstation.csv', delimiter=';', index_col=0)\n",
    "\n",
    "raw_data.columns = ['x_TS', 'y_TS', 'z_TS']\n",
    "data_positioning = data[\n",
    "    (data['Norm'] < 20) & \n",
    "    (data['x_Encoder'] < 2000) & \n",
    "    (data['x_Encoder'] > -1200) & \n",
    "    (data['y_Encoder'] < 8000) & \n",
    "    (data['z_Encoder'] > -1000) & \n",
    "    (data['z_Encoder'] < 2200)\n",
    "]\n",
    "data_positioning.index = data_positioning.index\n",
    "raw_data_positioning = raw_data[raw_data.index.isin(data_positioning.index)]\n",
    "ts_points_01_02 = raw_data_positioning[['x_TS','y_TS','z_TS']].sort_index()\n",
    "encoder_points_01_02 = data_positioning[['x_Encoder','y_Encoder','z_Encoder']].sort_index()/1000\n",
    "data_encoder_01_02 = data_positioning[['x_Encoder', 'y_Encoder', 'z_Encoder','encoder_0','encoder_1','encoder_2','encoder_3','encoder_4','encoder_5','encoder_6','encoder_7']].sort_index()\n",
    "used_indices = set(data_positioning.index)\n",
    "available_indices = list(set(data.index) - used_indices)\n",
    "selected_indices = np.random.choice(available_indices, 20, replace=False)\n",
    "validation_data_encoder_01_02 = data.loc[selected_indices].sort_index()\n",
    "validation_data_TS_01_02 = raw_data.loc[selected_indices].sort_index()\n",
    "encoder_points_validation_01_02 = validation_data_encoder_01_02[['x_Encoder', 'y_Encoder', 'z_Encoder']].values/1000 \n",
    "ts_points_validation_01_02 = validation_data_TS_01_02[['x_TS', 'y_TS', 'z_TS']].values\n",
    "\n",
    "# Daten vom 10.02.2025 importieren und strukturieren\n",
    "data = pd.read_csv('../data/Encoderwerte_Rohdaten_10_02_25.csv', delimiter=';',index_col=0)\n",
    "ts_points_10_02 = data[['x_TS', 'y_TS', 'z_TS']].sort_index()\n",
    "encoder_points_10_02 = data[['x_Encoder', 'y_Encoder','z_Encoder']].sort_index()\n",
    "data_encoder_10_02 = data[['x_Encoder', 'y_Encoder','z_Encoder','encoder_0','encoder_1','encoder_2','encoder_3','encoder_4','encoder_5','encoder_6','encoder_7']].sort_index()\n",
    "\n",
    "# Daten vom 25.02.2025 importieren und strukturieren\n",
    "data_TS_25_02 = pd.read_csv('../data/Rohdaten_TS_25_02_E_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "data_encoder_25_02 = pd.read_csv('../data/Encoderwerte_25_02_E_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "ts_points_25_02 = data_TS_25_02[['x_TS', 'y_TS', 'z_TS']]\n",
    "encoder_points_25_02 = data_encoder_25_02[['x_Encoder', 'y_Encoder','z_Encoder']]/1000\n",
    "validation_data_encoder_25_02 = pd.read_csv('../data/Encoderwerte_25_02_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_TS_25_02 = pd.read_csv('../data/Rohdaten_TS_25_02_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "encoder_points_validation_25_02 = validation_data_encoder_25_02[['x_Encoder', 'y_Encoder', 'z_Encoder']].values/1000\n",
    "ts_points_validation_25_02 = validation_data_TS_25_02[['x_TS', 'y_TS', 'z_TS']].values\n",
    "\n",
    "# Daten vom 03.03.2025 (Position 1) importieren und strukturieren\n",
    "data_TS_03_03 = pd.read_csv('../data/Rohdaten_TS_03_03_25_Position_1_Einmessung.csv', delimiter=';', index_col=0).sort_index()\n",
    "data_encoder_03_03 = pd.read_csv('../data/Encoderwerte_03_03_25_Position_1_Einmessung.csv', delimiter=';', index_col=0).sort_index()\n",
    "ts_points_03_03 = data_TS_03_03[['x_TS', 'y_TS', 'z_TS']]\n",
    "encoder_points_03_03 = data_encoder_03_03[['x_Encoder', 'y_Encoder','z_Encoder']]/1000\n",
    "validation_data_encoder_03_03 = pd.read_csv('../data/Encoderwerte_03_03_25_Position_1.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_TS_03_03 = pd.read_csv('../data/Rohdaten_TS_03_03_25_Position_1.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_encoder_03_03 = validation_data_encoder_03_03[~validation_data_encoder_03_03.index.str.endswith((\"second_stage_corrected\", \"first_stage_corrected\"))].sort_index()\n",
    "encoder_points_validation_03_03 = validation_data_encoder_03_03[['x_Encoder', 'y_Encoder', 'z_Encoder']].values/1000\n",
    "ts_points_validation_03_03 = validation_data_TS_03_03[['x_TS', 'y_TS', 'z_TS']].values\n",
    "\n",
    "# Daten vom 03.03.2025 (Position 2) importieren und strukturieren\n",
    "data_TS_03_03_2 = pd.read_csv('../data/Rohdaten_TS_03_03_25_Position_2_Einmessung.csv', delimiter=';', index_col=0).sort_index()\n",
    "data_encoder_03_03_2 = pd.read_csv('../data/Encoderwerte_03_03_25_Position_2_Einmessung.csv', delimiter=';', index_col=0).sort_index()\n",
    "ts_points_03_03_2 = data_TS_03_03_2[['x_TS', 'y_TS', 'z_TS']]\n",
    "encoder_points_03_03_2 = data_encoder_03_03_2[['x_Encoder', 'y_Encoder','z_Encoder']]/1000\n",
    "\n",
    "validation_data_encoder_03_03_2 = pd.read_csv('../data/Encoderwerte_03_03_25_Position_2.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_TS_03_03_2 = pd.read_csv('../data/Rohdaten_TS_03_03_25_Position_2.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_encoder_03_03_2 = validation_data_encoder_03_03_2[~validation_data_encoder_03_03_2.index.str.endswith((\"second_stage_corrected\", \"first_stage_corrected\"))].sort_index()\n",
    "encoder_points_validation_03_03_2 = validation_data_encoder_03_03_2[['x_Encoder', 'y_Encoder', 'z_Encoder']].values/1000\n",
    "ts_points_validation_03_03_2 = validation_data_TS_03_03_2[['x_TS', 'y_TS', 'z_TS']].values\n",
    "\n",
    "# Daten zusammenfassen\n",
    "datasets = {\n",
    "    '21_01': (encoder_points_21_01.values, ts_points_21_01.values),\n",
    "    '01_02': (encoder_points_01_02.values, ts_points_01_02.values),\n",
    "    '10_02': (encoder_points_10_02.values, ts_points_10_02.values), \n",
    "    '25_02': (encoder_points_25_02.values, ts_points_25_02.values),\n",
    "    '03_03_1': (encoder_points_03_03.values, ts_points_03_03.values),\n",
    "    '03_03_2': (encoder_points_03_03_2.values, ts_points_03_03_2.values),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd3e75",
   "metadata": {},
   "source": [
    "Transformationen und 3D-Vektorplot für jedes Datenset bestimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0403f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_total = pd.DataFrame()\n",
    "\n",
    "# For-Loop für die Transformation\n",
    "for day, (P, Q) in datasets.items():\n",
    "    # Schritt 1: Kabsch\n",
    "    R_est, t_est = kabsch_algorithm(P, Q)\n",
    "    \n",
    "    # Schritt 2: Least Squares Optimierung\n",
    "    x0 = np.array([0.0, 0.0, 0.0, t_est[0], t_est[1], t_est[2]])\n",
    "    result = least_squares(residual, x0, args=(P, Q), loss='huber', f_scale=1.0)\n",
    "    alpha_opt, beta_opt, gamma_opt, tx_opt, ty_opt, tz_opt = result.x\n",
    "    R_opt = rotation_matrix_from_euler(alpha_opt, beta_opt, gamma_opt)\n",
    "    t_opt = np.array([tx_opt, ty_opt, tz_opt])\n",
    "\n",
    "    # Schritt 3: Transformation der Encoderpunkte\n",
    "    P_transformed = (R_opt @ P.T).T + t_opt\n",
    "\n",
    "    # Schritt 4: Fehler (Vektoren)\n",
    "    deltas = (Q - P_transformed) * 1000  # Fehler in mm\n",
    "\n",
    "    if day != '10_02':\n",
    "        deltas_total = pd.concat([deltas_total, pd.DataFrame(deltas, columns=['x', 'y', 'z'])], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093cc9cc",
   "metadata": {},
   "source": [
    "Zusammenfassung aller Encoderwerte und Abweichungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb5cd9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoderwerte und Deltas in jeweils einem DataFrame zusammenfassen\n",
    "encoder_total = pd.concat([data_encoder_21_01, data_encoder_01_02, data_encoder_25_02, data_encoder_03_03, data_encoder_03_03_2])\n",
    "deltas_total.index = encoder_total.index\n",
    "encoder_total_1 = pd.concat([encoder_total, deltas_total], axis=1)\n",
    "encoder_total_1.columns = ['x_Encoder', 'y_Encoder', 'z_Encoder','encoder_0','encoder_1','encoder_2','encoder_3','encoder_4','encoder_5','encoder_6','encoder_7', 'delta_x', 'delta_y', 'delta_z']\n",
    "encoder_total_1['norm'] = np.linalg.norm(encoder_total_1[['delta_x', 'delta_y', 'delta_z']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc778f6",
   "metadata": {},
   "source": [
    "Cluster erstellen um Messpunkte zu filtern und auszuwählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8de4d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Clusterzentren definieren für KMeans\n",
    "centroids = np.array([\n",
    "    [-750, 7000, -250],   # Bottom-Back-Left\n",
    "    [750, 7000, -250],    # Bottom-Back-Right\n",
    "    [-750, 8000, -250],   # Bottom-Front-Left\n",
    "    [750, 8000, -250],    # Bottom-Front-Right\n",
    "    [-750, 7000, 1250],   # Top-Back-Left\n",
    "    [750, 7000, 1250],    # Top-Back-Right\n",
    "    [-750, 8000, 1250],   # Top-Front-Left\n",
    "    [750, 8000, 1250]     # Top-Front-Right\n",
    "])\n",
    "\n",
    "# Datenpunkte für KMeans\n",
    "data = encoder_total_1[['x_Encoder', 'y_Encoder', 'z_Encoder']].values\n",
    "\n",
    "# Nächstgelegenes Clusterzentrum für jeden Punkt finden\n",
    "neighbors = NearestNeighbors(n_neighbors=1)\n",
    "neighbors.fit(centroids)\n",
    "distances, indices = neighbors.kneighbors(data)\n",
    "\n",
    "# DataFrame erstellen mit den Datenpunkten und Clusterzugehörigkeit\n",
    "df_data = pd.DataFrame(data, columns=['x', 'y', 'z'], index=encoder_total_1.index)\n",
    "df_data['cluster'] = indices.flatten()\n",
    "\n",
    "encoder_total_1['cluster'] = df_data['cluster']\n",
    "\n",
    "# Nur Werte mit Norm < 12 mm behalten\n",
    "encoder_total_1 = encoder_total_1[encoder_total_1['norm'] < 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec5d810",
   "metadata": {},
   "source": [
    "3D-Vektorplot der geclusterten Einmesspunkte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbcc834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farben für jedes Cluster\n",
    "cluster_colors = {\n",
    "    0: \"rgb(230, 25, 75)\",    # Rot\n",
    "    1: \"rgb(0, 130, 200)\",    # Blau\n",
    "    2: \"rgb(60, 180, 75)\",    # Grün\n",
    "    3: \"rgb(255, 140, 0)\",    # Orange\n",
    "    4: \"rgb(145, 30, 180)\",   # Lila\n",
    "    5: \"rgb(0, 190, 255)\",    # Hellblau\n",
    "    6: \"rgb(255, 225, 25)\",   # Gelb\n",
    "    7: \"rgb(245, 50, 150)\"    # Pink\n",
    "}\n",
    "\n",
    "# Positionen der Colorbars\n",
    "colorbar_positions = {\n",
    "    0: (0.85, 1),\n",
    "    1: (0.85, 0.75),\n",
    "    2: (0.85, 0.5),\n",
    "    3: (0.85, 0.25),\n",
    "    4: (0.95, 1),\n",
    "    5: (0.95, 0.75),\n",
    "    6: (0.95, 0.5),\n",
    "    7: (0.95, 0.25)\n",
    "}\n",
    "\n",
    "# Plot anlegen\n",
    "fig = go.Figure()\n",
    "sizeref_factor = 10  # Skalieren der Pfeilgrößen\n",
    "\n",
    "# For-Loop für die Erstellung der Datenpunkte des 3D-Plots\n",
    "for cluster_id in sorted(encoder_total_1['cluster'].unique()):\n",
    "    cluster_df = encoder_total_1[encoder_total_1['cluster'] == cluster_id]\n",
    "    color = cluster_colors.get(cluster_id, \"rgb(150, 150, 150)\") \n",
    "    x_bar, y_bar = colorbar_positions.get(cluster_id, (1.0, 0.5))\n",
    "\n",
    "    quiver = go.Cone(\n",
    "        x=cluster_df[\"x_Encoder\"],\n",
    "        y=cluster_df[\"y_Encoder\"],\n",
    "        z=cluster_df[\"z_Encoder\"],\n",
    "        u=cluster_df[\"delta_x\"],\n",
    "        v=cluster_df[\"delta_y\"],\n",
    "        w=cluster_df[\"delta_z\"],\n",
    "        opacity=1,\n",
    "        sizemode=\"raw\",\n",
    "        sizeref=sizeref_factor,\n",
    "        colorscale=[[0, color], [1, color]],\n",
    "        showscale=True,\n",
    "        colorbar=dict(\n",
    "            title=f\"Cluster {cluster_id}\",\n",
    "            len=0.25,\n",
    "            x=x_bar,\n",
    "            y=y_bar\n",
    "        ),\n",
    "        name=f\"Cluster {cluster_id}\"\n",
    "    )\n",
    "\n",
    "    fig.add_trace(quiver)\n",
    "\n",
    "# Layout anpassen\n",
    "fig.update_layout(\n",
    "    title='3D Vektorplot der geclusterten Einmesspunkte',\n",
    "    scene=dict(\n",
    "        xaxis_title=\"<i>x</i> in mm\",\n",
    "        yaxis_title=\"<i>y</i> in mm\",\n",
    "        zaxis_title=\"<i>z</i> in mm\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot speichern\n",
    "fig.write_html(\"../results/Diagramme/Einmessverfahren/3D_Vektorplot_Cluster_Einmesspunkte.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc304ee1",
   "metadata": {},
   "source": [
    "Auswahl 5 zufälliger Werte aus jedem Cluster zur Implementierung des Einmessverfahrens in die Maschinensteuerung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87c5c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der zu samplenden Punkte pro Cluster\n",
    "n_samples = 5\n",
    "\n",
    "# Leere Liste für die gesampelten Punkte\n",
    "sampled_points = []\n",
    "\n",
    "# For-Loop für die Auswahl der Punkte aus jedem Cluster\n",
    "for cluster_id in range(8):\n",
    "    # Datenpunkte des Clusters auswählen\n",
    "    cluster_data = encoder_total_1[encoder_total_1['cluster'] == cluster_id]\n",
    "    \n",
    "    # Zufällige Auswahl der Punkte\n",
    "    sampled_cluster = cluster_data.sample(n=min(n_samples, len(cluster_data)), random_state=42)\n",
    "    \n",
    "    # An Liste anhängen\n",
    "    sampled_points.append(sampled_cluster)\n",
    "\n",
    "# Zusammenführen der gesampelten Punkte in einen DataFrame\n",
    "df_sampled = pd.concat(sampled_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a7ad3a",
   "metadata": {},
   "source": [
    "Plotten der gefilterten Punkte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "083d0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeref_factor = 10  # Adjust this factor for desired visual scaling\n",
    "\n",
    "# Create vectors (quivers) for errors before transformation\n",
    "quivers_sampled_points = go.Cone(\n",
    "    x=df_sampled[\"x_Encoder\"],\n",
    "    y=df_sampled[\"y_Encoder\"],\n",
    "    z=df_sampled[\"z_Encoder\"],\n",
    "    u=df_sampled['delta_x'],\n",
    "    v=df_sampled['delta_y'],\n",
    "    w=df_sampled['delta_z'],\n",
    "    opacity= 1,\n",
    "    sizemode=\"raw\",\n",
    "    sizeref=sizeref_factor,  # Use calculated sizeref for errors before\n",
    "    colorscale='Reds',\n",
    "    colorbar=dict(\n",
    "        title=\"Abweichung in mm\",\n",
    "        len=0.5,  # Length of the colorbar\n",
    "        x=0.85,   # Position on the x-axis\n",
    "        y=0.7   # Position on the y-axis\n",
    "    ),\n",
    "    name='Einmesspunkte'\n",
    ")\n",
    "\n",
    "# Create the figure and add traces\n",
    "fig = go.Figure(data=[quivers_sampled_points])\n",
    "\n",
    "# Set plot layout\n",
    "fig.update_layout(\n",
    "    title='3D Vektorplot der finalen Einmesspunkte',\n",
    "    scene=dict(\n",
    "        xaxis_title=\"<i>x</i> in mm\",\n",
    "        yaxis_title='<i>y</i> in mm',\n",
    "        zaxis_title='<i>z</i> in mm'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save the plot to an HTML file\n",
    "fig.write_html(\"../results/Diagramme/Einmessverfahren/3D_Vektorplot_Zusammenfassung_Einmesspunkte.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f8b8c",
   "metadata": {},
   "source": [
    "Umrechnung der Winkel in Radianten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "192a1aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\si159\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in arccos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "positioning_points = pd.DataFrame(columns=['x_Encoder', 'y_Encoder', 'z_Encoder', 'encoder_0', 'encoder_1', 'encoder_2', 'encoder_3', 'encoder_4', 'encoder_5', 'encoder_6', 'encoder_7'],index=df_sampled.index)\n",
    "positioning_points[['x_Encoder', 'y_Encoder', 'z_Encoder','cluster']] = df_sampled[['x_Encoder', 'y_Encoder', 'z_Encoder','cluster']]\n",
    "positioning_points['encoder_0'] = gelenk0_TF(df_sampled['encoder_0'])\n",
    "positioning_points['encoder_1'] = gelenk1_TF(df_sampled['encoder_1'])\n",
    "positioning_points['encoder_2'] = gelenk2_TF(df_sampled['encoder_2'])\n",
    "positioning_points['encoder_3'] = gelenk3_TF(df_sampled['encoder_3'])\n",
    "positioning_points['encoder_4'] = gelenk4_TF(df_sampled['encoder_4'])\n",
    "positioning_points['encoder_5'] = gelenk5_TF(df_sampled['encoder_5'])\n",
    "positioning_points['encoder_6'] = gelenk6_TF(df_sampled['encoder_6'])\n",
    "positioning_points['encoder_7'] = gelenk7_TF(df_sampled['encoder_7'])\n",
    "positioning_points.index.name = 'ID'\n",
    "positioning_points.to_csv('../results/Tabellen/Einmesspunkte_Encoderstellungen.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
