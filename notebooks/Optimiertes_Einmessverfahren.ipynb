{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "from scipy.optimize import least_squares\n",
    "import plotly.graph_objects as go\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktionen importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kabsch_algorithm(P, Q):\n",
    "    p_centroid = np.mean(P, axis=0)\n",
    "    q_centroid = np.mean(Q, axis=0)\n",
    "    P_centered = P - p_centroid # Werte werden ins Zentrum des Koordinatensystems verschoben\n",
    "    Q_centered = Q - q_centroid # Werte werden ins Zentrum des Koordinatensystems verschoben\n",
    "    H = P_centered.T @ Q_centered # Korrelationsmatrix\n",
    "    U, S, Vt = svd(H)\n",
    "    V = Vt.T\n",
    "    R = V @ U.T\n",
    "    if np.linalg.det(R) < 0:\n",
    "        V[:,-1] *= -1\n",
    "        R = V @ U.T\n",
    "    t = q_centroid - R @ p_centroid\n",
    "    return R, t\n",
    "\n",
    "def rotation_matrix_from_euler(alpha, beta, gamma):\n",
    "    # Rotationsmatrizen für Eulerwinkel (Z-Y-X)\n",
    "    Rz = np.array([[np.cos(alpha), -np.sin(alpha), 0],\n",
    "                   [np.sin(alpha),  np.cos(alpha), 0],\n",
    "                   [0,              0,             1]])\n",
    "    Ry = np.array([[ np.cos(beta), 0, np.sin(beta)],\n",
    "                   [0,             1, 0],\n",
    "                   [-np.sin(beta), 0, np.cos(beta)]])\n",
    "    Rx = np.array([[1,             0,              0],\n",
    "                   [0, np.cos(gamma), -np.sin(gamma)],\n",
    "                   [0, np.sin(gamma),  np.cos(gamma)]])\n",
    "    return Rz @ Ry @ Rx\n",
    "\n",
    "def residual(params, P, Q):\n",
    "    alpha, beta, gamma, tx, ty, tz = params\n",
    "    R_opt = rotation_matrix_from_euler(alpha, beta, gamma)\n",
    "    t_opt = np.array([tx, ty, tz])\n",
    "    P_transformed = (R_opt @ P.T).T + t_opt\n",
    "    diff = P_transformed - Q\n",
    "    return diff.flatten()\n",
    "\n",
    "# Introduce noise into 10 random data points\n",
    "def add_noise_to_random_points(data, noise_level=0.01, num_points=10):\n",
    "    indices = np.random.choice(data.shape[0], num_points, replace=False)\n",
    "    noise = np.random.normal(0, noise_level, (num_points, data.shape[1]))\n",
    "    data_noisy = data.copy()\n",
    "    data_noisy[indices] += noise\n",
    "    return data_noisy\n",
    "\n",
    "def angular_difference(angle1, angle2):\n",
    "    \"\"\"Berechnet minimalen Winkelunterschied in Grad.\"\"\"\n",
    "    diff = np.abs(angle1 - angle2) % 360\n",
    "    return np.minimum(diff, 360 - diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messdaten aller Messtage 21.01., 01.02., 10.02., 03.03. (Position 1) und 03.03. (Position 2) importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten vom 21.01.2025 importieren und strukturieren\n",
    "data_ts_21_01 = pd.read_csv('../data/Rohdaten_TS_21_01_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "data_encoder_21_01 = pd.read_csv('../data/Encoderwerte_21_01_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_TS_21_01 = pd.read_csv('../data/Rohdaten_TS_21_01_V_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_encoder_21_01 = pd.read_csv('../data/Encoderwerte_21_01_V_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "\n",
    "encoder_points_21_01 = (data_encoder_21_01[['x_Encoder', 'y_Encoder', 'z_Encoder']]/1000)\n",
    "ts_points_21_01 = data_ts_21_01[['x_TS', 'y_TS', 'z_TS']]\n",
    "\n",
    "encoder_points_validation_21_01 = validation_data_encoder_21_01[['x_Encoder', 'y_Encoder', 'z_Encoder']].values/1000\n",
    "ts_points_validation_21_01 = validation_data_TS_21_01[['x_TS', 'y_TS', 'z_TS']].values \n",
    "\n",
    "# Daten vom 01.02.2025 importieren und strukturieren\n",
    "data = pd.read_csv('../data/Modellentwicklung_Encoderwerte.csv', sep=';', index_col=0)\n",
    "raw_data = pd.read_csv('../data/Modellentwicklung_Rohdaten_Totalstation.csv', delimiter=';', index_col=0)\n",
    "\n",
    "raw_data.columns = ['x_TS', 'y_TS', 'z_TS']\n",
    "data_positioning = data[\n",
    "    (data['Norm'] < 20) & \n",
    "    (data['x_Encoder'] < 2000) & \n",
    "    (data['x_Encoder'] > -1200) & \n",
    "    (data['y_Encoder'] < 8000) & \n",
    "    (data['z_Encoder'] > -1000) & \n",
    "    (data['z_Encoder'] < 2200)\n",
    "]\n",
    "data_positioning.index = data_positioning.index\n",
    "raw_data_positioning = raw_data[raw_data.index.isin(data_positioning.index)]\n",
    "ts_points_01_02 = raw_data_positioning[['x_TS','y_TS','z_TS']].sort_index()\n",
    "encoder_points_01_02 = data_positioning[['x_Encoder','y_Encoder','z_Encoder']].sort_index()/1000\n",
    "data_encoder_01_02 = data_positioning[['x_Encoder', 'y_Encoder', 'z_Encoder','encoder_0','encoder_1','encoder_2','encoder_3','encoder_4','encoder_5','encoder_6','encoder_7']].sort_index()\n",
    "used_indices = set(data_positioning.index)\n",
    "available_indices = list(set(data.index) - used_indices)\n",
    "selected_indices = np.random.choice(available_indices, 20, replace=False)\n",
    "validation_data_encoder_01_02 = data.loc[selected_indices].sort_index()\n",
    "validation_data_TS_01_02 = raw_data.loc[selected_indices].sort_index()\n",
    "encoder_points_validation_01_02 = validation_data_encoder_01_02[['x_Encoder', 'y_Encoder', 'z_Encoder']].values/1000 \n",
    "ts_points_validation_01_02 = validation_data_TS_01_02[['x_TS', 'y_TS', 'z_TS']].values\n",
    "\n",
    "# Daten vom 10.02.2025 importieren und strukturieren\n",
    "data = pd.read_csv('../data/Encoderwerte_Rohdaten_10_02_25.csv', delimiter=';',index_col=0)\n",
    "ts_points_10_02 = data[['x_TS', 'y_TS', 'z_TS']].sort_index()\n",
    "encoder_points_10_02 = data[['x_Encoder', 'y_Encoder','z_Encoder']].sort_index()\n",
    "data_encoder_10_02 = data[['x_Encoder', 'y_Encoder','z_Encoder','encoder_0','encoder_1','encoder_2','encoder_3','encoder_4','encoder_5','encoder_6','encoder_7']].sort_index()\n",
    "\n",
    "# Daten vom 25.02.2025 importieren und strukturieren\n",
    "data_TS_25_02 = pd.read_csv('../data/Rohdaten_TS_25_02_E_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "data_encoder_25_02 = pd.read_csv('../data/Encoderwerte_25_02_E_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "ts_points_25_02 = data_TS_25_02[['x_TS', 'y_TS', 'z_TS']]\n",
    "encoder_points_25_02 = data_encoder_25_02[['x_Encoder', 'y_Encoder','z_Encoder']]/1000\n",
    "validation_data_encoder_25_02 = pd.read_csv('../data/Encoderwerte_25_02_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_TS_25_02 = pd.read_csv('../data/Rohdaten_TS_25_02_25.csv', delimiter=';', index_col=0).sort_index()\n",
    "encoder_points_validation_25_02 = validation_data_encoder_25_02[['x_Encoder', 'y_Encoder', 'z_Encoder']].values/1000\n",
    "ts_points_validation_25_02 = validation_data_TS_25_02[['x_TS', 'y_TS', 'z_TS']].values\n",
    "\n",
    "# Daten vom 03.03.2025 (Position 1) importieren und strukturieren\n",
    "data_TS_03_03 = pd.read_csv('../data/Rohdaten_TS_03_03_25_Position_1_Einmessung.csv', delimiter=';', index_col=0).sort_index()\n",
    "data_encoder_03_03 = pd.read_csv('../data/Encoderwerte_03_03_25_Position_1_Einmessung.csv', delimiter=';', index_col=0).sort_index()\n",
    "ts_points_03_03 = data_TS_03_03[['x_TS', 'y_TS', 'z_TS']]\n",
    "encoder_points_03_03 = data_encoder_03_03[['x_Encoder', 'y_Encoder','z_Encoder']]/1000\n",
    "validation_data_encoder_03_03 = pd.read_csv('../data/Encoderwerte_03_03_25_Position_1.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_TS_03_03 = pd.read_csv('../data/Rohdaten_TS_03_03_25_Position_1.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_encoder_03_03 = validation_data_encoder_03_03[~validation_data_encoder_03_03.index.str.endswith((\"second_stage_corrected\", \"first_stage_corrected\"))].sort_index()\n",
    "encoder_points_validation_03_03 = validation_data_encoder_03_03[['x_Encoder', 'y_Encoder', 'z_Encoder']].values/1000\n",
    "ts_points_validation_03_03 = validation_data_TS_03_03[['x_TS', 'y_TS', 'z_TS']].values\n",
    "\n",
    "# Daten vom 03.03.2025 (Position 2) importieren und strukturieren\n",
    "data_TS_03_03_2 = pd.read_csv('../data/Rohdaten_TS_03_03_25_Position_2_Einmessung.csv', delimiter=';', index_col=0).sort_index()\n",
    "data_encoder_03_03_2 = pd.read_csv('../data/Encoderwerte_03_03_25_Position_2_Einmessung.csv', delimiter=';', index_col=0).sort_index()\n",
    "ts_points_03_03_2 = data_TS_03_03_2[['x_TS', 'y_TS', 'z_TS']]\n",
    "encoder_points_03_03_2 = data_encoder_03_03_2[['x_Encoder', 'y_Encoder','z_Encoder']]/1000\n",
    "\n",
    "validation_data_encoder_03_03_2 = pd.read_csv('../data/Encoderwerte_03_03_25_Position_2.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_TS_03_03_2 = pd.read_csv('../data/Rohdaten_TS_03_03_25_Position_2.csv', delimiter=';', index_col=0).sort_index()\n",
    "validation_data_encoder_03_03_2 = validation_data_encoder_03_03_2[~validation_data_encoder_03_03_2.index.str.endswith((\"second_stage_corrected\", \"first_stage_corrected\"))].sort_index()\n",
    "encoder_points_validation_03_03_2 = validation_data_encoder_03_03_2[['x_Encoder', 'y_Encoder', 'z_Encoder']].values/1000\n",
    "ts_points_validation_03_03_2 = validation_data_TS_03_03_2[['x_TS', 'y_TS', 'z_TS']].values\n",
    "\n",
    "# Daten zusammenfassen\n",
    "datasets = {\n",
    "    '21_01': (encoder_points_21_01.values, ts_points_21_01.values),\n",
    "    '01_02': (encoder_points_01_02.values, ts_points_01_02.values),\n",
    "    '10_02': (encoder_points_10_02.values, ts_points_10_02.values), \n",
    "    '25_02': (encoder_points_25_02.values, ts_points_25_02.values),\n",
    "    '03_03_1': (encoder_points_03_03.values, ts_points_03_03.values),\n",
    "    '03_03_2': (encoder_points_03_03_2.values, ts_points_03_03_2.values),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformationen und 3D-Vektorplot für jedes Datenset bestimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farben für den Vektorplot definieren\n",
    "colors = {\n",
    "    '21_01': 'red',\n",
    "    '01_02': 'blue',\n",
    "    '10_02': 'green',\n",
    "    '25_02': 'orange',\n",
    "    '03_03_1': 'purple',\n",
    "    '03_03_2': 'cyan'\n",
    "}\n",
    "\n",
    "# 3D Vektorplot erstellen\n",
    "fig = go.Figure()\n",
    "\n",
    "# Variablen für den for-Loop initialisieren\n",
    "transformations = {}\n",
    "counter = 0\n",
    "x_space = 0\n",
    "deltas_total = pd.DataFrame()\n",
    "\n",
    "# For-Loop für die Transformation und den Vektorplot\n",
    "for day, (P, Q) in datasets.items():\n",
    "    # Schritt 1: Kabsch\n",
    "    R_est, t_est = kabsch_algorithm(P, Q)\n",
    "    \n",
    "    # Schritt 2: Least Squares Optimierung\n",
    "    x0 = np.array([0.0, 0.0, 0.0, t_est[0], t_est[1], t_est[2]])\n",
    "    result = least_squares(residual, x0, args=(P, Q), loss='huber', f_scale=1.0)\n",
    "    alpha_opt, beta_opt, gamma_opt, tx_opt, ty_opt, tz_opt = result.x\n",
    "    R_opt = rotation_matrix_from_euler(alpha_opt, beta_opt, gamma_opt)\n",
    "    t_opt = np.array([tx_opt, ty_opt, tz_opt])\n",
    "\n",
    "    # Schritt 3: Transformation der Encoderpunkte\n",
    "    P_transformed = (R_opt @ P.T).T + t_opt\n",
    "\n",
    "    # Schritt 4: Fehler (Vektoren)\n",
    "    deltas = (Q - P_transformed) * 1000  # Fehler in mm\n",
    "\n",
    "    # Lage des Farbbars anpassen\n",
    "    if counter > 2:\n",
    "        x_space = 0.1\n",
    "        counter = 0\n",
    "\n",
    "    # Schritt 5: Vektorplot erstellen\n",
    "    quiver = go.Cone(\n",
    "        x=P[:, 0]*1000,\n",
    "        y=P[:, 1]*1000,\n",
    "        z=P[:, 2]*1000,\n",
    "        u=deltas[:, 0],\n",
    "        v=deltas[:, 1],\n",
    "        w=deltas[:, 2],\n",
    "        opacity=0.5,\n",
    "        sizemode=\"raw\",\n",
    "        sizeref=10,  # Anpassen für bessere Sichtbarkeit\n",
    "        colorscale=[[0, colors[day]], [1, colors[day]]],\n",
    "        colorbar=dict(\n",
    "            title=f'Abweichung<br>{day} (mm)',\n",
    "            len=0.33,\n",
    "            x=0.85 + x_space,  # Verschieben nach rechts\n",
    "            y=0.9 - counter*0.33,\n",
    "        ),\n",
    "        showscale=True,\n",
    "        name=f'{day}'\n",
    "    )\n",
    "\n",
    "    fig.add_trace(quiver)\n",
    "\n",
    "    # Rotationsmatrix, Translation, Eulerwinkel und Deltas in Variablen speichern \n",
    "    transformations[day] = {'R': R_opt, 't': t_opt, 'Euler': np.degrees([alpha_opt, beta_opt, gamma_opt])}\n",
    "    if day != '10_02':\n",
    "        deltas_total = pd.concat([deltas_total, pd.DataFrame(deltas, columns=['x', 'y', 'z'])], axis=0)\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "# Schritt 6: Vektorplot-Layout anpassen\n",
    "fig.update_layout(\n",
    "    title='3D Vektorplot aller Einmessungen',\n",
    "    scene=dict(\n",
    "        xaxis_title=\"<i>x</i> in mm\",\n",
    "        yaxis_title=\"<i>y</i> in mm\",\n",
    "        zaxis_title=\"<i>z</i> in mm\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Schritt 7: Vektorplot speichern\n",
    "fig.write_html(\"../results/Diagramme/Einmessverfahren/3D_Vektorplot_alle_Einmessungen.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnung der Transformationsunterschiede der unterschiedlichen Messtage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Vergleich  Roll Unterschied (°)  Pitch Unterschied (°)  \\\n",
      "0    21_01 vs 01_02              0.060356               0.004998   \n",
      "1    21_01 vs 10_02              0.077657               0.136672   \n",
      "2    21_01 vs 25_02              0.056914               0.301892   \n",
      "3  21_01 vs 03_03_1              0.056955               0.386203   \n",
      "4    01_02 vs 10_02              0.017301               0.141670   \n",
      "5    01_02 vs 25_02              0.003442               0.306890   \n",
      "6  01_02 vs 03_03_1              0.003401               0.391201   \n",
      "7    10_02 vs 25_02              0.020744               0.165220   \n",
      "8  10_02 vs 03_03_1              0.020702               0.249531   \n",
      "9  25_02 vs 03_03_1              0.000041               0.084311   \n",
      "\n",
      "   Yaw Unterschied (°)  Translationsunterschied (mm)  \n",
      "0             0.109252                     16.200062  \n",
      "1             0.018782                      5.644995  \n",
      "2             0.115442                     14.087826  \n",
      "3             0.135720                     10.773888  \n",
      "4             0.090470                     12.591040  \n",
      "5             0.224694                     23.639066  \n",
      "6             0.244972                     18.044751  \n",
      "7             0.134224                     18.435346  \n",
      "8             0.154502                     14.185040  \n",
      "9             0.020278                      5.617766  \n"
     ]
    }
   ],
   "source": [
    "# Nur relevante Tage verwenden\n",
    "relevant_days = [day for day in transformations.keys() if day != '03_03_2']\n",
    "\n",
    "# Alle Kombinationen aus zwei verschiedenen relevanten Tagen bilden\n",
    "comparison_pairs = list(itertools.combinations(relevant_days, 2))\n",
    "\n",
    "# Ergebnisse speichern\n",
    "results = []\n",
    "\n",
    "for day1, day2 in comparison_pairs:\n",
    "    euler1 = transformations[day1]['Euler']\n",
    "    euler2 = transformations[day2]['Euler']\n",
    "    t1 = transformations[day1]['t']\n",
    "    t2 = transformations[day2]['t']\n",
    "\n",
    "    # Richtiger Rotationsunterschied:\n",
    "    diff_roll = angular_difference(euler1[0], euler2[0])\n",
    "    diff_pitch = angular_difference(euler1[1], euler2[1])\n",
    "    diff_yaw = angular_difference(euler1[2], euler2[2])\n",
    "\n",
    "    # Translationsunterschied\n",
    "    translation_diff = np.linalg.norm((t1 - t2) * 1000)\n",
    "\n",
    "    results.append({\n",
    "        'Vergleich': f'{day1} vs {day2}',\n",
    "        'Roll Unterschied (°)': diff_roll,\n",
    "        'Pitch Unterschied (°)': diff_pitch,\n",
    "        'Yaw Unterschied (°)': diff_yaw,\n",
    "        'Translationsunterschied (mm)': translation_diff\n",
    "    })\n",
    "\n",
    "# In DataFrame umwandeln\n",
    "df_comparison = pd.DataFrame(results)\n",
    "\n",
    "# Schön ausgeben\n",
    "print(df_comparison)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
